{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split as sklearn_split\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import pickle\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 | Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, val_size=0.2, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Divide os dados em treino, validação e teste.\n",
    "    \"\"\"\n",
    "    train_data, temp_data = sklearn_split(\n",
    "        data, test_size=(val_size + test_size), random_state=random_state\n",
    "    )\n",
    "    val_data, test_data = sklearn_split(\n",
    "        temp_data,\n",
    "        test_size=(test_size / (val_size + test_size)),\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_surprise_data(data):\n",
    "    \"\"\"\n",
    "    Prepara os dados no formato esperado pelo pacote surprise.\n",
    "    \"\"\"\n",
    "    reader = Reader(rating_scale=(0, 1))\n",
    "    return Dataset.load_from_df(\n",
    "        data[[\"customer_id\", \"offer_id\", \"total_offer_completed\"]], reader\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_funk_svd(train_data):\n",
    "    \"\"\"\n",
    "    Treina o modelo FunkSVD usando os dados de treino.\n",
    "    \"\"\"\n",
    "    # Divide os dados no formato surprise\n",
    "    train_set, test_set = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Configura e treina o modelo\n",
    "    model = SVD(n_factors=50, random_state=42)\n",
    "    model.fit(train_set)\n",
    "\n",
    "    # Avalia o modelo no conjunto de teste\n",
    "    predictions = model.test(test_set)\n",
    "    test_rmse = accuracy.rmse(predictions)\n",
    "\n",
    "    return model, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_validation(model, val_data):\n",
    "    \"\"\"\n",
    "    Faz as predições no conjunto de validação e retorna a métrica RMSE.\n",
    "    \"\"\"\n",
    "    val_predictions = [\n",
    "        model.predict(row[\"customer_id\"], row[\"offer_id\"], row[\"total_offer_completed\"])\n",
    "        for _, row in val_data.iterrows()\n",
    "    ]\n",
    "\n",
    "    val_rmse = accuracy.rmse(val_predictions, verbose=False)\n",
    "    return val_predictions, val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_offers_per_customer(predictions):\n",
    "    \"\"\"\n",
    "    Retorna as 3 ofertas com maior probabilidade de aceite para cada cliente no conjunto de validação.\n",
    "    \"\"\"\n",
    "    pred_df = pd.DataFrame(\n",
    "        predictions,\n",
    "        columns=[\"customer_id\", \"offer_id\", \"actual\", \"predicted\", \"details\"],\n",
    "    )\n",
    "\n",
    "    pred_df = pred_df.sort_values(\n",
    "        by=[\"customer_id\", \"predicted\"], ascending=[True, False]\n",
    "    )\n",
    "\n",
    "    return pred_df[[\"customer_id\", \"offer_id\", \"predicted\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_arpu_estimado(predictions, arpu_data, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Estima o ARPU com base nas predições do modelo e nos valores históricos de ARPU.\n",
    "\n",
    "    Parâmetros:\n",
    "        predictions: Predições geradas pelo modelo no conjunto de validação.\n",
    "        arpu_data: DataFrame com o histórico de ARPU por oferta.\n",
    "        threshold: Probabilidade mínima para considerar uma oferta aceita.\n",
    "\n",
    "    Retorna:\n",
    "        estimated_arpu: ARPU médio estimado para as ofertas recomendadas.\n",
    "        impact_analysis: Análise do impacto potencial no negócio.\n",
    "    \"\"\"\n",
    "    pred_df = pd.DataFrame(\n",
    "        predictions,\n",
    "        columns=[\"customer_id\", \"offer_id\", \"actual\", \"predicted\", \"details\"],\n",
    "    )\n",
    "\n",
    "    # Filter the offer based on the threshold probabilities\n",
    "    high_prob_offers = pred_df[pred_df[\"predicted\"] >= threshold]\n",
    "\n",
    "    # Merge with historical ARPU data\n",
    "    high_prob_offers = high_prob_offers.merge(\n",
    "        arpu_data[[\"offer_id\", \"arpu\"]], on=\"offer_id\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Get the estimated average ARPU weighted by predicted probabilities\n",
    "    total_weighted_arpu = (\n",
    "        high_prob_offers[\"predicted\"] * high_prob_offers[\"arpu\"]\n",
    "    ).sum()\n",
    "    total_customers = high_prob_offers[\"customer_id\"].nunique()\n",
    "    estimated_arpu = total_weighted_arpu / total_customers if total_customers > 0 else 0\n",
    "\n",
    "    # Calcular impacto no ARPU por oferta\n",
    "    arpu_by_offer = (\n",
    "        high_prob_offers.groupby(\"offer_id\")\n",
    "        .apply(\n",
    "            lambda x: (\n",
    "                (x[\"predicted\"] * x[\"arpu\"]).sum() / x[\"customer_id\"].nunique()\n",
    "                if x[\"customer_id\"].nunique() > 0\n",
    "                else 0\n",
    "            )\n",
    "        )\n",
    "        .reset_index(name=\"estimated_arpu_per_offer\")\n",
    "    )\n",
    "\n",
    "    # Adicionar ARPU histórico às ofertas para comparação\n",
    "    arpu_by_offer = arpu_by_offer.merge(\n",
    "        arpu_data[[\"offer_id\", \"arpu\"]], on=\"offer_id\", how=\"left\"\n",
    "    )\n",
    "    arpu_by_offer[\"impact_percentage\"] = (\n",
    "        (arpu_by_offer[\"estimated_arpu_per_offer\"] - arpu_by_offer[\"arpu\"])\n",
    "        / arpu_by_offer[\"arpu\"]\n",
    "    ) * 100\n",
    "\n",
    "    # Análise de impacto geral\n",
    "    average_historical_arpu = arpu_data[\"arpu\"].mean()\n",
    "    improvement = (\n",
    "        (estimated_arpu - average_historical_arpu) / average_historical_arpu * 100\n",
    "    )\n",
    "\n",
    "    impact_analysis = {\n",
    "        \"estimated_arpu\": estimated_arpu,\n",
    "        \"average_historical_arpu\": average_historical_arpu,\n",
    "        \"improvement_percentage\": improvement,\n",
    "        \"arpu_by_offer\": arpu_by_offer,\n",
    "    }\n",
    "\n",
    "    return estimated_arpu, impact_analysis, total_weighted_arpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 | Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_id</th>\n",
       "      <th>offer_id_mapping</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>total_customers</th>\n",
       "      <th>arpu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0b1e1539f2cc45b7b9fa7c272da2e1d7</td>\n",
       "      <td>6</td>\n",
       "      <td>3975808.70</td>\n",
       "      <td>144909</td>\n",
       "      <td>27.4366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2298d6c36e964ae4a3e7e9706d1fb8c2</td>\n",
       "      <td>7</td>\n",
       "      <td>7783803.46</td>\n",
       "      <td>154828</td>\n",
       "      <td>50.2739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2906b810c7d4411798c6938adc9daaa5</td>\n",
       "      <td>1</td>\n",
       "      <td>5433365.93</td>\n",
       "      <td>145660</td>\n",
       "      <td>37.3017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3f207df678b143eea3cee63160fa8bed</td>\n",
       "      <td>2</td>\n",
       "      <td>2980827.33</td>\n",
       "      <td>140564</td>\n",
       "      <td>21.2062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4d5c57ea9a6940dd891ad53e9dbe8da0</td>\n",
       "      <td>9</td>\n",
       "      <td>6534407.03</td>\n",
       "      <td>150664</td>\n",
       "      <td>43.3707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           offer_id  offer_id_mapping  total_amount  \\\n",
       "0  0b1e1539f2cc45b7b9fa7c272da2e1d7                 6    3975808.70   \n",
       "1  2298d6c36e964ae4a3e7e9706d1fb8c2                 7    7783803.46   \n",
       "2  2906b810c7d4411798c6938adc9daaa5                 1    5433365.93   \n",
       "3  3f207df678b143eea3cee63160fa8bed                 2    2980827.33   \n",
       "4  4d5c57ea9a6940dd891ad53e9dbe8da0                 9    6534407.03   \n",
       "\n",
       "   total_customers     arpu  \n",
       "0           144909  27.4366  \n",
       "1           154828  50.2739  \n",
       "2           145660  37.3017  \n",
       "3           140564  21.2062  \n",
       "4           150664  43.3707  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_arpu = pd.read_csv(\"../data/final/historical_arpu.csv\")\n",
    "hist_arpu = hist_arpu.drop(columns=\"Unnamed: 0\")\n",
    "hist_arpu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_offers_agg = pd.read_csv(\n",
    "    \"../data/final/customer_offers_agg.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_offers_agg = customers_offers_agg.sort_values(by=[\"customer_id\", \"offer_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 | Prepare data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in train, test and validation, without prepare to surprise package\n",
    "train_raw, val_raw, test_raw = split_data(customers_offers_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara data to surprise package\n",
    "surprise_train = prepare_surprise_data(train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 | Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model, test_rmse = train_funk_svd(surprise_train)\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle file\n",
    "model_pkl_file = \"../models/funksvd.pkl\"  \n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalualiation of the model in the validtion set\n",
    "val_predictions, val_rmse = evaluate_validation(model, val_raw)\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 3 offers for a customer\n",
    "best_offers = top_offers_per_customer(val_predictions)\n",
    "print(\"\\nMelhores Ofertas por Cliente:\")\n",
    "best_offers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo implementado foi o funkSVD:\n",
    "\n",
    "- A versão implementada do modelo foi a mais simples, visto que utilizou apenas os dados necessários, i.e., sem a adição de nenhuma variável latente/explicativa\n",
    "\n",
    "- O modelo também não teve os seus parâmetros ajustados\n",
    "\n",
    "- O funkSVD foi escolhido devido a facilidade de implementação e, também, pelas características do modelo (robusto quando aplicado em dados esparsos, escalável para grandes conjuntos de dados, permite regularização, etc). Ele é utilizado para prever a probabiliade de aceitação de ofertas não vistas por um cliente. O modelo utiliza apenas a matriz  de interações (```customer_id```, ```offer_id``` e ```total_offer_completed```)\n",
    "\n",
    "Logo o modelo poderia ser melhorado das seguintes formas: \n",
    "\n",
    "- Adicionar a otimização dos hiperpârametros do modelo:\n",
    "\t•\tn_factors: Dimensão dos fatores latentes.\n",
    "\t•\treg_all: Regularização para evitar overfitting.\n",
    "\t•\tlearning_rate: Taxa de aprendizado.\n",
    "\n",
    "- Adicionar variáveis explicativas ao modelo:\n",
    "    •\tFunkSVD + Modelos Baseados em Features: Após gerar as predições do FunkSVD, incluímos outras features em um modelo secundário, como uma regressão ou árvore de decisão.\n",
    "\t•\tConcatenação de Latent Factors e Features Adicionais: Após treinar o FunkSVD, usamos os fatores latentes gerados (usuário e item) como entrada para um modelo supervisionado, junto com as outras features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados foram separados em três: dados de treino, teste e validação do modelo. Os dados de validação serão utilizados para estimar o impacto do modelo no ARPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 | ARPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo mensuramos o impacto no ARPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARPU Estimado: 58.88\n",
      "ARPU Histórico Médio: 46.36\n",
      "Melhoria Estimada: 27.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/mv_nh0ks2n98r3d6kxb3tdh40000gn/T/ipykernel_5785/2271383863.py:36: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  high_prob_offers.groupby(\"offer_id\")\n"
     ]
    }
   ],
   "source": [
    "estimated_arpu, impact_analysis, total_weighted_arpu = calcular_arpu_estimado(\n",
    "    val_predictions, hist_arpu, threshold=0.5\n",
    ")\n",
    "\n",
    "# Exibir os resultados\n",
    "print(f\"ARPU Estimado: {impact_analysis['estimated_arpu']:.2f}\")\n",
    "print(f\"ARPU Histórico Médio: {impact_analysis['average_historical_arpu']:.2f}\")\n",
    "print(f\"Melhoria Estimada: {impact_analysis['improvement_percentage']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_arpu[\"arpu\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estimar o impacto geral no ARPU, será utilizado os resultados do modelo funkSVD e da abordagem de top 3 ofertas tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 offers with the best ARPU\n",
    "n_noinfo_top_3 = 2174\n",
    "arpu_estimated_top_3 = 65.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpu_ml = estimated_arpu\n",
    "n_ml = customers_offers_agg.customer_id.nunique() - n_noinfo_top_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.75919380946227"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arpu_total = (arpu_ml * n_ml + arpu_estimated_top_3 * n_noinfo_top_3) / (\n",
    "    n_noinfo_top_3 + n_ml\n",
    ")\n",
    "arpu_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
